{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfof/nHI6QEZC/FXc1tjq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barassah/Datasets/blob/main/BERT_Apple_Dataset_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zAxeFyCaw4R9"
      },
      "outputs": [],
      "source": [
        "#loading libraries\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "vzqfHYAAxDn7",
        "outputId": "cf30679a-bff7-41bd-cb98-4fb0eab7bba6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cfed28eb-6a7f-4ecd-9bc9-305a20d0e7a5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cfed28eb-6a7f-4ecd-9bc9-305a20d0e7a5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Apple-Twitter-Sentiment-DFE.csv to Apple-Twitter-Sentiment-DFE.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading and describing the dataset\n",
        "dataset=pd.read_csv(\"Apple-Twitter-Sentiment-DFE.csv\", encoding='ISO-8859-1')\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1fXMapZxFZA",
        "outputId": "977f69eb-16e3-4377-b7e3-f1e93d309d8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
            "0     623495513     True      golden                  10               NaN   \n",
            "1     623495514     True      golden                  12               NaN   \n",
            "2     623495515     True      golden                  10               NaN   \n",
            "3     623495516     True      golden                  17               NaN   \n",
            "4     623495517    False   finalized                   3    12/12/14 12:14   \n",
            "...         ...      ...         ...                 ...               ...   \n",
            "3881  623499442     True      golden                  13               NaN   \n",
            "3882  623499450     True      golden                  16               NaN   \n",
            "3883  623499486     True      golden                  14               NaN   \n",
            "3884  623499514     True      golden                  13               NaN   \n",
            "3885  623517290     True      golden                  17               NaN   \n",
            "\n",
            "     sentiment  sentiment:confidence                            date  \\\n",
            "0            3                0.6264  Mon Dec 01 19:30:03 +0000 2014   \n",
            "1            3                0.8129  Mon Dec 01 19:43:51 +0000 2014   \n",
            "2            3                1.0000  Mon Dec 01 19:50:28 +0000 2014   \n",
            "3            3                0.5848  Mon Dec 01 20:26:34 +0000 2014   \n",
            "4            3                0.6474  Mon Dec 01 20:29:33 +0000 2014   \n",
            "...        ...                   ...                             ...   \n",
            "3881         3                0.7757  Tue Dec 09 22:08:53 +0000 2014   \n",
            "3882         3                0.6225  Tue Dec 09 22:18:27 +0000 2014   \n",
            "3883         5                0.9347  Tue Dec 09 23:45:59 +0000 2014   \n",
            "3884         1                0.9230  Wed Dec 10 00:48:10 +0000 2014   \n",
            "3885         5                0.8938  Tue Dec 09 09:01:25 +0000 2014   \n",
            "\n",
            "                id            query      sentiment_gold  \\\n",
            "0     5.400000e+17  #AAPL OR @Apple     3\\nnot_relevant   \n",
            "1     5.400000e+17  #AAPL OR @Apple                3\\n1   \n",
            "2     5.400000e+17  #AAPL OR @Apple                   3   \n",
            "3     5.400000e+17  #AAPL OR @Apple                3\\n1   \n",
            "4     5.400000e+17  #AAPL OR @Apple                 NaN   \n",
            "...            ...              ...                 ...   \n",
            "3881  5.420000e+17  #AAPL OR @Apple                5\\n3   \n",
            "3882  5.420000e+17  #AAPL OR @Apple                3\\n1   \n",
            "3883  5.420000e+17  #AAPL OR @Apple                   5   \n",
            "3884  5.420000e+17  #AAPL OR @Apple                   1   \n",
            "3885  5.420000e+17  #AAPL OR @Apple  5\\n3\\nnot_relevant   \n",
            "\n",
            "                                                   text  \n",
            "0     #AAPL:The 10 best Steve Jobs emails ever...htt...  \n",
            "1     RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...  \n",
            "2     My cat only chews @apple cords. Such an #Apple...  \n",
            "3     I agree with @jimcramer that the #IndividualIn...  \n",
            "4          Nobody expects the Spanish Inquisition #AAPL  \n",
            "...                                                 ...  \n",
            "3881  (Via FC) Apple Is Warming Up To Social Media -...  \n",
            "3882  RT @MMLXIV: there is no avocado emoji may I as...  \n",
            "3883  @marcbulandr I could not agree more. Between @...  \n",
            "3884  My iPhone 5's photos are no longer downloading...  \n",
            "3885  RT @SwiftKey: We're so excited to be named to ...  \n",
            "\n",
            "[3886 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHoeNjF1xThd",
        "outputId": "b089aa79-7226-404e-eb63-1512edc8511f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3886 entries, 0 to 3885\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   _unit_id              3886 non-null   int64  \n",
            " 1   _golden               3886 non-null   bool   \n",
            " 2   _unit_state           3886 non-null   object \n",
            " 3   _trusted_judgments    3886 non-null   int64  \n",
            " 4   _last_judgment_at     3783 non-null   object \n",
            " 5   sentiment             3886 non-null   object \n",
            " 6   sentiment:confidence  3886 non-null   float64\n",
            " 7   date                  3886 non-null   object \n",
            " 8   id                    3886 non-null   float64\n",
            " 9   query                 3886 non-null   object \n",
            " 10  sentiment_gold        103 non-null    object \n",
            " 11  text                  3886 non-null   object \n",
            "dtypes: bool(1), float64(2), int64(2), object(7)\n",
            "memory usage: 337.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2MHxS_3xYI8",
        "outputId": "d35f0718-b2af-4219-9c72-854b950bccec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3886, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6zh7l1txbGy",
        "outputId": "03692e9f-2aa3-4820-df40-3e0e22cdb7a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
              "       '_last_judgment_at', 'sentiment', 'sentiment:confidence', 'date', 'id',\n",
              "       'query', 'sentiment_gold', 'text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-Prcoessing and Bag of Word Vectorization using Count Vectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "textCount = cv.fit_transform(dataset['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwJ8TjaExdXB",
        "outputId": "d119c027-8a8f-48e3-a09a-269e5ed681b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using textblob to understand review sentiment since, the data was unlabeled\n",
        "from textblob import Word, TextBlob\n",
        "dataset['sentiment']=dataset['text'].apply(lambda x: TextBlob(x).sentiment[0])\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "D_7Imw3XyvBP",
        "outputId": "2d831aaf-80a0-4f12-f5cd-b801d9a420d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/colab/_dataframe_summarizer.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  cast_date_col = pd.to_datetime(column, errors=\"coerce\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
              "0  623495513     True      golden                  10               NaN   \n",
              "1  623495514     True      golden                  12               NaN   \n",
              "2  623495515     True      golden                  10               NaN   \n",
              "3  623495516     True      golden                  17               NaN   \n",
              "4  623495517    False   finalized                   3    12/12/14 12:14   \n",
              "\n",
              "   sentiment  sentiment:confidence                            date  \\\n",
              "0       1.00                0.6264  Mon Dec 01 19:30:03 +0000 2014   \n",
              "1       0.00                0.8129  Mon Dec 01 19:43:51 +0000 2014   \n",
              "2       0.00                1.0000  Mon Dec 01 19:50:28 +0000 2014   \n",
              "3       0.65                0.5848  Mon Dec 01 20:26:34 +0000 2014   \n",
              "4       0.00                0.6474  Mon Dec 01 20:29:33 +0000 2014   \n",
              "\n",
              "             id            query   sentiment_gold  \\\n",
              "0  5.400000e+17  #AAPL OR @Apple  3\\nnot_relevant   \n",
              "1  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
              "2  5.400000e+17  #AAPL OR @Apple                3   \n",
              "3  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
              "4  5.400000e+17  #AAPL OR @Apple              NaN   \n",
              "\n",
              "                                                text  \n",
              "0  #AAPL:The 10 best Steve Jobs emails ever...htt...  \n",
              "1  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...  \n",
              "2  My cat only chews @apple cords. Such an #Apple...  \n",
              "3  I agree with @jimcramer that the #IndividualIn...  \n",
              "4       Nobody expects the Spanish Inquisition #AAPL  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6ff444f-5044-4ca5-8edb-9dae06e498fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>_golden</th>\n",
              "      <th>_unit_state</th>\n",
              "      <th>_trusted_judgments</th>\n",
              "      <th>_last_judgment_at</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment:confidence</th>\n",
              "      <th>date</th>\n",
              "      <th>id</th>\n",
              "      <th>query</th>\n",
              "      <th>sentiment_gold</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>623495513</td>\n",
              "      <td>True</td>\n",
              "      <td>golden</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.6264</td>\n",
              "      <td>Mon Dec 01 19:30:03 +0000 2014</td>\n",
              "      <td>5.400000e+17</td>\n",
              "      <td>#AAPL OR @Apple</td>\n",
              "      <td>3\\nnot_relevant</td>\n",
              "      <td>#AAPL:The 10 best Steve Jobs emails ever...htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>623495514</td>\n",
              "      <td>True</td>\n",
              "      <td>golden</td>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.8129</td>\n",
              "      <td>Mon Dec 01 19:43:51 +0000 2014</td>\n",
              "      <td>5.400000e+17</td>\n",
              "      <td>#AAPL OR @Apple</td>\n",
              "      <td>3\\n1</td>\n",
              "      <td>RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>623495515</td>\n",
              "      <td>True</td>\n",
              "      <td>golden</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Mon Dec 01 19:50:28 +0000 2014</td>\n",
              "      <td>5.400000e+17</td>\n",
              "      <td>#AAPL OR @Apple</td>\n",
              "      <td>3</td>\n",
              "      <td>My cat only chews @apple cords. Such an #Apple...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>623495516</td>\n",
              "      <td>True</td>\n",
              "      <td>golden</td>\n",
              "      <td>17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.5848</td>\n",
              "      <td>Mon Dec 01 20:26:34 +0000 2014</td>\n",
              "      <td>5.400000e+17</td>\n",
              "      <td>#AAPL OR @Apple</td>\n",
              "      <td>3\\n1</td>\n",
              "      <td>I agree with @jimcramer that the #IndividualIn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>623495517</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>12/12/14 12:14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.6474</td>\n",
              "      <td>Mon Dec 01 20:29:33 +0000 2014</td>\n",
              "      <td>5.400000e+17</td>\n",
              "      <td>#AAPL OR @Apple</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nobody expects the Spanish Inquisition #AAPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6ff444f-5044-4ca5-8edb-9dae06e498fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6ff444f-5044-4ca5-8edb-9dae06e498fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6ff444f-5044-4ca5-8edb-9dae06e498fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e3bae3ed-7482-4cef-a7a2-0c8bc8b883aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3bae3ed-7482-4cef-a7a2-0c8bc8b883aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e3bae3ed-7482-4cef-a7a2-0c8bc8b883aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 3886,\n  \"fields\": [\n    {\n      \"column\": \"_unit_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1171,\n        \"min\": 623495513,\n        \"max\": 623517290,\n        \"num_unique_values\": 3886,\n        \"samples\": [\n          623496868,\n          623498417,\n          623499122\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_golden\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_unit_state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"finalized\",\n          \"golden\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_trusted_judgments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 3,\n        \"max\": 27,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          10,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"_last_judgment_at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2014-12-11 08:18:00\",\n        \"max\": \"2014-12-12 22:32:00\",\n        \"num_unique_values\": 388,\n        \"samples\": [\n          \"12/11/14 19:05\",\n          \"12/12/14 7:04\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30162786670992353,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 405,\n        \"samples\": [\n          0.30000000000000004,\n          0.20000000000000004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment:confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17586424491712324,\n        \"min\": 0.3327,\n        \"max\": 1.0,\n        \"num_unique_values\": 654,\n        \"samples\": [\n          0.649,\n          0.6816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3795,\n        \"samples\": [\n          \"Tue Dec 02 15:25:08 +0000 2014\",\n          \"Mon Dec 08 19:49:25 +0000 2014\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 794275221427271.1,\n        \"min\": 5.4e+17,\n        \"max\": 5.42e+17,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5.4e+17,\n          5.41e+17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"#AAPL OR @Apple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_gold\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"3\\n1\\nnot_relevant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3219,\n        \"samples\": [\n          \"APPLE - Fibonacci Technicals Levels - Intraday  Update - $AAPL #aapl \\r\\nhttp://t.co/EyE2GtZ2g5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m=dataset.sentiment\n",
        "np.unique(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD-Hyz3dy6XN",
        "outputId": "2e0ac673-cced-4b94-8db7-5f159b9898d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.00000000e+00, -9.37500000e-01, -9.00000000e-01, -8.00000000e-01,\n",
              "       -7.81250000e-01, -7.80000000e-01, -7.50000000e-01, -7.38281250e-01,\n",
              "       -7.32421875e-01, -7.16666667e-01, -7.14285714e-01, -7.00000000e-01,\n",
              "       -7.00000000e-01, -7.00000000e-01, -6.66666667e-01, -6.50000000e-01,\n",
              "       -6.25000000e-01, -6.00000000e-01, -6.00000000e-01, -6.00000000e-01,\n",
              "       -5.90000000e-01, -5.85937500e-01, -5.83333333e-01, -5.62500000e-01,\n",
              "       -5.50000000e-01, -5.33333333e-01, -5.25000000e-01, -5.04166667e-01,\n",
              "       -5.00000000e-01, -5.00000000e-01, -4.83333333e-01, -4.66666667e-01,\n",
              "       -4.57142857e-01, -4.50000000e-01, -4.50000000e-01, -4.43988715e-01,\n",
              "       -4.37500000e-01, -4.33333333e-01, -4.27083333e-01, -4.00000000e-01,\n",
              "       -4.00000000e-01, -4.00000000e-01, -3.96666667e-01, -3.90625000e-01,\n",
              "       -3.88888889e-01, -3.87500000e-01, -3.77777778e-01, -3.75000000e-01,\n",
              "       -3.75000000e-01, -3.75000000e-01, -3.72916667e-01, -3.66666667e-01,\n",
              "       -3.62500000e-01, -3.54545455e-01, -3.50000000e-01, -3.50000000e-01,\n",
              "       -3.33854167e-01, -3.33333333e-01, -3.32323232e-01, -3.31250000e-01,\n",
              "       -3.25000000e-01, -3.22222222e-01, -3.21527778e-01, -3.16666667e-01,\n",
              "       -3.12500000e-01, -3.06818182e-01, -3.00000000e-01, -3.00000000e-01,\n",
              "       -2.91666667e-01, -2.87878788e-01, -2.82142857e-01, -2.76190476e-01,\n",
              "       -2.66666667e-01, -2.63541667e-01, -2.62500000e-01, -2.56250000e-01,\n",
              "       -2.50000000e-01, -2.50000000e-01, -2.43750000e-01, -2.37037037e-01,\n",
              "       -2.34615385e-01, -2.33333333e-01, -2.31818182e-01, -2.26666667e-01,\n",
              "       -2.25000000e-01, -2.25000000e-01, -2.19047619e-01, -2.18750000e-01,\n",
              "       -2.16666667e-01, -2.15625000e-01, -2.05000000e-01, -2.00000000e-01,\n",
              "       -2.00000000e-01, -2.00000000e-01, -1.95833333e-01, -1.94444444e-01,\n",
              "       -1.93750000e-01, -1.87500000e-01, -1.81818182e-01, -1.75000000e-01,\n",
              "       -1.71759259e-01, -1.67857143e-01, -1.66666667e-01, -1.62878788e-01,\n",
              "       -1.56250000e-01, -1.55555556e-01, -1.54545455e-01, -1.50000000e-01,\n",
              "       -1.50000000e-01, -1.45833333e-01, -1.41666667e-01, -1.40000000e-01,\n",
              "       -1.34722222e-01, -1.33333333e-01, -1.31818182e-01, -1.27777778e-01,\n",
              "       -1.25000000e-01, -1.25000000e-01, -1.25000000e-01, -1.12500000e-01,\n",
              "       -1.12500000e-01, -1.01636905e-01, -1.00000000e-01, -1.00000000e-01,\n",
              "       -1.00000000e-01, -9.16666667e-02, -8.80952381e-02, -8.78787879e-02,\n",
              "       -8.75000000e-02, -8.33333333e-02, -8.18181818e-02, -7.69230769e-02,\n",
              "       -7.65151515e-02, -7.57575758e-02, -7.50000000e-02, -7.50000000e-02,\n",
              "       -7.14285714e-02, -6.81818182e-02, -6.66666667e-02, -6.66666667e-02,\n",
              "       -6.25000000e-02, -6.19047619e-02, -6.00000000e-02, -5.62500000e-02,\n",
              "       -5.55555556e-02, -5.00000000e-02, -5.00000000e-02, -5.00000000e-02,\n",
              "       -4.58333333e-02, -4.24242424e-02, -4.16666667e-02, -3.75000000e-02,\n",
              "       -3.33333333e-02, -3.33333333e-02, -3.05555556e-02, -2.77777778e-02,\n",
              "       -2.50000000e-02, -2.50000000e-02, -2.12121212e-02, -1.78571429e-02,\n",
              "       -1.66666667e-02, -1.66666667e-02, -1.66666667e-02, -1.59090909e-02,\n",
              "       -1.51515152e-02, -1.33928571e-02, -1.25000000e-02, -1.25000000e-02,\n",
              "       -1.00000000e-02, -8.33333333e-03,  0.00000000e+00,  5.55111512e-17,\n",
              "        2.08333333e-03,  5.68181818e-03,  8.33333333e-03,  1.21212121e-02,\n",
              "        1.25000000e-02,  1.66666667e-02,  1.66666667e-02,  1.66666667e-02,\n",
              "        1.81818182e-02,  2.22222222e-02,  2.22222222e-02,  2.45535714e-02,\n",
              "        2.50000000e-02,  2.66666667e-02,  2.85714286e-02,  2.97619048e-02,\n",
              "        3.12500000e-02,  3.27380952e-02,  3.33333333e-02,  3.33333333e-02,\n",
              "        3.33333333e-02,  3.33333333e-02,  3.58585859e-02,  3.75000000e-02,\n",
              "        4.26136364e-02,  4.28571429e-02,  4.31818182e-02,  4.44444444e-02,\n",
              "        4.46428571e-02,  5.00000000e-02,  5.00000000e-02,  5.83333333e-02,\n",
              "        6.21212121e-02,  6.25000000e-02,  6.56250000e-02,  6.62878788e-02,\n",
              "        6.66666667e-02,  6.81818182e-02,  7.22222222e-02,  7.31481481e-02,\n",
              "        7.50000000e-02,  7.50000000e-02,  7.50000000e-02,  7.50000000e-02,\n",
              "        7.77777778e-02,  7.87878788e-02,  8.33333333e-02,  8.33333333e-02,\n",
              "        8.52272727e-02,  8.88888889e-02,  8.97727273e-02,  9.16666667e-02,\n",
              "        9.50000000e-02,  9.52380952e-02,  9.94318182e-02,  1.00000000e-01,\n",
              "        1.00000000e-01,  1.00000000e-01,  1.00000000e-01,  1.02500000e-01,\n",
              "        1.02777778e-01,  1.04166667e-01,  1.04166667e-01,  1.05519481e-01,\n",
              "        1.07142857e-01,  1.12121212e-01,  1.12121212e-01,  1.12500000e-01,\n",
              "        1.13636364e-01,  1.14814815e-01,  1.16666667e-01,  1.18181818e-01,\n",
              "        1.18750000e-01,  1.19047619e-01,  1.22916667e-01,  1.25000000e-01,\n",
              "        1.31250000e-01,  1.33333333e-01,  1.34090909e-01,  1.36363636e-01,\n",
              "        1.36507937e-01,  1.38624339e-01,  1.40000000e-01,  1.45454545e-01,\n",
              "        1.50000000e-01,  1.50000000e-01,  1.53409091e-01,  1.56250000e-01,\n",
              "        1.61904762e-01,  1.62121212e-01,  1.66666667e-01,  1.66666667e-01,\n",
              "        1.68181818e-01,  1.68750000e-01,  1.70454545e-01,  1.71428571e-01,\n",
              "        1.73674242e-01,  1.75000000e-01,  1.78787879e-01,  1.80000000e-01,\n",
              "        1.83333333e-01,  1.83333333e-01,  1.87500000e-01,  1.89682540e-01,\n",
              "        1.93181818e-01,  2.00000000e-01,  2.00000000e-01,  2.00000000e-01,\n",
              "        2.08333333e-01,  2.12121212e-01,  2.12500000e-01,  2.14285714e-01,\n",
              "        2.16666667e-01,  2.16666667e-01,  2.18750000e-01,  2.20833333e-01,\n",
              "        2.25000000e-01,  2.25000000e-01,  2.27272727e-01,  2.33333333e-01,\n",
              "        2.45312500e-01,  2.45454545e-01,  2.46590909e-01,  2.50000000e-01,\n",
              "        2.50000000e-01,  2.52777778e-01,  2.55113636e-01,  2.68181818e-01,\n",
              "        2.71428571e-01,  2.72222222e-01,  2.72500000e-01,  2.73611111e-01,\n",
              "        2.75000000e-01,  2.81250000e-01,  2.85714286e-01,  2.87272727e-01,\n",
              "        2.87500000e-01,  2.88095238e-01,  2.88888889e-01,  2.92613636e-01,\n",
              "        3.00000000e-01,  3.00000000e-01,  3.08333333e-01,  3.11111111e-01,\n",
              "        3.12121212e-01,  3.12500000e-01,  3.12500000e-01,  3.18181818e-01,\n",
              "        3.25000000e-01,  3.33333333e-01,  3.37500000e-01,  3.40000000e-01,\n",
              "        3.50000000e-01,  3.50000000e-01,  3.55555556e-01,  3.56534091e-01,\n",
              "        3.57142857e-01,  3.57142857e-01,  3.59090909e-01,  3.62121212e-01,\n",
              "        3.64583333e-01,  3.66666667e-01,  3.68181818e-01,  3.70606061e-01,\n",
              "        3.75000000e-01,  3.77777778e-01,  3.90625000e-01,  3.92857143e-01,\n",
              "        3.98437500e-01,  4.00000000e-01,  4.00000000e-01,  4.08333333e-01,\n",
              "        4.11111111e-01,  4.12121212e-01,  4.16666667e-01,  4.16666667e-01,\n",
              "        4.18181818e-01,  4.18750000e-01,  4.21875000e-01,  4.25000000e-01,\n",
              "        4.28571429e-01,  4.33333333e-01,  4.33333333e-01,  4.36904762e-01,\n",
              "        4.37500000e-01,  4.42857143e-01,  4.42857143e-01,  4.46428571e-01,\n",
              "        4.50000000e-01,  4.66666667e-01,  4.66666667e-01,  4.68181818e-01,\n",
              "        4.73484848e-01,  4.75000000e-01,  4.75000000e-01,  4.85227273e-01,\n",
              "        5.00000000e-01,  5.20833333e-01,  5.25000000e-01,  5.28787879e-01,\n",
              "        5.33333333e-01,  5.46875000e-01,  5.50000000e-01,  5.50000000e-01,\n",
              "        5.56463068e-01,  5.61904762e-01,  5.62500000e-01,  5.66666667e-01,\n",
              "        5.66666667e-01,  5.68181818e-01,  5.87500000e-01,  6.00000000e-01,\n",
              "        6.00000000e-01,  6.25000000e-01,  6.41666667e-01,  6.50000000e-01,\n",
              "        6.50000000e-01,  6.66666667e-01,  6.87500000e-01,  7.00000000e-01,\n",
              "        7.12500000e-01,  7.19140625e-01,  7.33333333e-01,  7.50000000e-01,\n",
              "        7.50000000e-01,  7.66666667e-01,  7.75000000e-01,  7.81250000e-01,\n",
              "        8.00000000e-01,  8.50000000e-01,  8.75000000e-01,  8.76837158e-01,\n",
              "        1.00000000e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_sentiment(value, threshold):\n",
        "    if value > threshold:\n",
        "        return '1'\n",
        " #   elif value > pos_threshold:\n",
        " #       return '2'\n",
        "    else:\n",
        "        return '0'\n",
        "\n",
        "# Example thresholds\n",
        "#threshold = 0.0  # Adjust as needed\n",
        "threshold = 0.0   # Adjust as needed\n",
        "\n",
        "# Categorize sentiment values and store them back in the DataFrame\n",
        "dataset['polarity'] = dataset['sentiment'].apply(lambda x: categorize_sentiment(x, threshold)\n",
        "\n",
        ")\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQg9s58Ey72N",
        "outputId": "a992eb62-8fb2-40dc-e48e-18691d1b0478"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
            "0     623495513     True      golden                  10               NaN   \n",
            "1     623495514     True      golden                  12               NaN   \n",
            "2     623495515     True      golden                  10               NaN   \n",
            "3     623495516     True      golden                  17               NaN   \n",
            "4     623495517    False   finalized                   3    12/12/14 12:14   \n",
            "...         ...      ...         ...                 ...               ...   \n",
            "3881  623499442     True      golden                  13               NaN   \n",
            "3882  623499450     True      golden                  16               NaN   \n",
            "3883  623499486     True      golden                  14               NaN   \n",
            "3884  623499514     True      golden                  13               NaN   \n",
            "3885  623517290     True      golden                  17               NaN   \n",
            "\n",
            "      sentiment  sentiment:confidence                            date  \\\n",
            "0      1.000000                0.6264  Mon Dec 01 19:30:03 +0000 2014   \n",
            "1      0.000000                0.8129  Mon Dec 01 19:43:51 +0000 2014   \n",
            "2      0.000000                1.0000  Mon Dec 01 19:50:28 +0000 2014   \n",
            "3      0.650000                0.5848  Mon Dec 01 20:26:34 +0000 2014   \n",
            "4      0.000000                0.6474  Mon Dec 01 20:29:33 +0000 2014   \n",
            "...         ...                   ...                             ...   \n",
            "3881   0.022222                0.7757  Tue Dec 09 22:08:53 +0000 2014   \n",
            "3882   0.000000                0.6225  Tue Dec 09 22:18:27 +0000 2014   \n",
            "3883   0.433333                0.9347  Tue Dec 09 23:45:59 +0000 2014   \n",
            "3884   0.000000                0.9230  Wed Dec 10 00:48:10 +0000 2014   \n",
            "3885   0.687500                0.8938  Tue Dec 09 09:01:25 +0000 2014   \n",
            "\n",
            "                id            query      sentiment_gold  \\\n",
            "0     5.400000e+17  #AAPL OR @Apple     3\\nnot_relevant   \n",
            "1     5.400000e+17  #AAPL OR @Apple                3\\n1   \n",
            "2     5.400000e+17  #AAPL OR @Apple                   3   \n",
            "3     5.400000e+17  #AAPL OR @Apple                3\\n1   \n",
            "4     5.400000e+17  #AAPL OR @Apple                 NaN   \n",
            "...            ...              ...                 ...   \n",
            "3881  5.420000e+17  #AAPL OR @Apple                5\\n3   \n",
            "3882  5.420000e+17  #AAPL OR @Apple                3\\n1   \n",
            "3883  5.420000e+17  #AAPL OR @Apple                   5   \n",
            "3884  5.420000e+17  #AAPL OR @Apple                   1   \n",
            "3885  5.420000e+17  #AAPL OR @Apple  5\\n3\\nnot_relevant   \n",
            "\n",
            "                                                   text polarity  \n",
            "0     #AAPL:The 10 best Steve Jobs emails ever...htt...        1  \n",
            "1     RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...        0  \n",
            "2     My cat only chews @apple cords. Such an #Apple...        0  \n",
            "3     I agree with @jimcramer that the #IndividualIn...        1  \n",
            "4          Nobody expects the Spanish Inquisition #AAPL        0  \n",
            "...                                                 ...      ...  \n",
            "3881  (Via FC) Apple Is Warming Up To Social Media -...        1  \n",
            "3882  RT @MMLXIV: there is no avocado emoji may I as...        0  \n",
            "3883  @marcbulandr I could not agree more. Between @...        1  \n",
            "3884  My iPhone 5's photos are no longer downloading...        0  \n",
            "3885  RT @SwiftKey: We're so excited to be named to ...        1  \n",
            "\n",
            "[3886 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['polarity'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "8wLM_FneRiF8",
        "outputId": "dcc7ce38-d0d0-4d45-a83f-30b56ab82677"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "polarity\n",
              "0    2708\n",
              "1    1178\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>polarity</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation sets\n",
        "train_df, val_df = train_test_split(dataset, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Z_Zn4fI-xuMs"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenize the text\n",
        "def tokenize_data(df, max_length=128):\n",
        "    return tokenizer(\n",
        "        dataset[\"text\"].tolist(),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "train_encodings = tokenize_data(train_df)\n",
        "val_encodings = tokenize_data(val_df)\n"
      ],
      "metadata": {
        "id": "30xHeMsCB0OT"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to tensors\n",
        "import torch\n",
        "\n",
        "# Convert polarity values to integers\n",
        "train_df[\"polarity\"] = pd.to_numeric(train_df[\"polarity\"])\n",
        "val_df[\"polarity\"] = pd.to_numeric(val_df[\"polarity\"])\n",
        "\n",
        "# Create tensors\n",
        "train_labels = torch.tensor(train_df[\"polarity\"].tolist())\n",
        "val_labels = torch.tensor(val_df[\"polarity\"].tolist())"
      ],
      "metadata": {
        "id": "BWY8Jr2hB7kc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ReviewDataset(train_encodings, train_labels)\n",
        "val_dataset = ReviewDataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "biGU-vGACcX6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZZTwn4ZCh7N",
        "outputId": "48faf836-7102-446e-d586-c44729875a47"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "print(\"Training Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZbK7DEpClg5",
        "outputId": "4054affc-6a0e-4e9e-f6ac-972078502e63"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "sC1YBu80CrvR",
        "outputId": "33016089-b38b-4f32-a74d-89ac70e3a98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='460' max='585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [460/585 1:47:25 < 29:19, 0.07 it/s, Epoch 2.35/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.625700</td>\n",
              "      <td>0.623717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.658500</td>\n",
              "      <td>0.620836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "print(results)"
      ],
      "metadata": {
        "id": "ELYCFvR2VleX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Application of the Model**"
      ],
      "metadata": {
        "id": "TOq-BYs1WIqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    return torch.argmax(probs).item()\n",
        "\n",
        "# Example prediction\n",
        "text = \"This is a fake review.\"\n",
        "prediction = predict(text)\n",
        "print(\"Fake\" if prediction == 1 else \"Genuine\")"
      ],
      "metadata": {
        "id": "TWdQQ394VvGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./fake_review_detection_model\")\n",
        "tokenizer.save_pretrained(\"./fake_review_detection_model\")"
      ],
      "metadata": {
        "id": "YkqBhXtXV7mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hs2Omuf8V8lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZ5l5ogcV87f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Load BERT tokenizer\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenize the text\n",
        "# def tokenize_data(df, max_length=128):\n",
        "#    return tokenizer(\n",
        "#        df[\"text\"].tolist(),\n",
        "#        padding=True,\n",
        "#        truncation=True,\n",
        "#        max_length=max_length,\n",
        "#        return_tensors=\"pt\",\n",
        "#    )\n",
        "\n",
        "#train_encodings = tokenize_data(train_df)\n",
        "#val_encodings = tokenize_data(val_df)\n",
        "\n",
        "#print(\"Tokenize Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9yIfL_vx5_p",
        "outputId": "83dc0fcf-a146-4296-ceb0-931523063a3f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to tensors\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch"
      ],
      "metadata": {
        "id": "pspR_5Lsx7IW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the label encoder on training labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_df[\"text\"])\n",
        "\n",
        "# Map unseen labels to -1\n",
        "def transform_with_unseen(labels, encoder):\n",
        "    unseen_label = -1\n",
        "    labels = np.array(labels)\n",
        "    transformed = np.array([encoder.transform([label])[0] if label in encoder.classes_ else unseen_label for label in labels])\n",
        "    return transformed\n",
        "\n",
        "# Transform the labels\n",
        "train_labels = transform_with_unseen(train_df[\"polarity\"], label_encoder)\n",
        "val_labels = transform_with_unseen(val_df[\"polarity\"], label_encoder)\n",
        "\n",
        "# Convert to tensors\n",
        "train_labels_tensor = torch.tensor(train_labels)\n",
        "val_labels_tensor = torch.tensor(val_labels)\n",
        "\n",
        "print(train_labels_tensor)\n",
        "print(val_labels_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhdUml-fyLdy",
        "outputId": "b3cba74c-8236-4786-ed6b-70b6919f6b63"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1, -1, -1,  ..., -1, -1, -1])\n",
            "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
            "        -1, -1, -1, -1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aFXv4qFxBRfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "#from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments\n",
        "# Load the tokenizer and model\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WygZ43EyOEo",
        "outputId": "65f76126-c9e7-433e-c79b-cad77da117cc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "print(\"End of training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJp741z5zgvF",
        "outputId": "2525de83-8fff-4b42-ea35-57bb3d3c260e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming you have your model, training_args, train_dataset, and val_dataset defined\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_labels_tensor,\n",
        "    eval_dataset=val_labels_tensor,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(\"training done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "zzqQu4D8zplK",
        "outputId": "01479c94-3ef2-4bf4-ccdd-4b897a229c90"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,token_type_ids,position_ids,head_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,labels,label,label_ids.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-9096e7360390>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2522\u001b[0m                     )\n\u001b[1;32m   2523\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3646\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3648\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3650\u001b[0m             \u001b[0mloss_mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmp_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3595\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3596\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3597\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3598\u001b[0m                 \u001b[0;34m\"The batch received was empty, your model won't be able to train on it. Double-check that your \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3599\u001b[0m                 \u001b[0;34mf\"training dataset contains keys expected by the model: {','.join(self._signature_columns)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,token_type_ids,position_ids,head_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,labels,label,label_ids."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13iFCWyjzswx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}